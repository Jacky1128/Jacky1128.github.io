<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="robots" content="index, follow" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Zedong Wang, 王泽栋, machine learning, westlake university">
<link rel="stylesheet" href="./Files/jemdoc.css" type="text/css" />
<script src="jquery.min.js"></script>
<link rel="shortcut icon" href="./Files/HKUST.ico">
<title>Zedong Wang</title>
<script async defer src="https://buttons.github.io/buttons.js"></script>
</head>


<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable"><tr><td>
<a href="./" style="color:#1F5CCA"><img src="./Files/wangzedong.jpg" alt="" height="220px" /></a>&nbsp;</td>
<td align="left"><p><a href="./" style="color:#1F50C0"><font size="4">Zedong Wang (</font><font size="4"; font style="font-family:Microsoft YaHei">王泽栋</font><font size="4">)</font></a><br />
<i> <a href="https://en.westlake.edu.cn" target="_blank" style="color:#1F28E6">Westlake University</a></i>
<br /><br />
<!-- <a href="https://www.zju.edu.cn/" target="_blank">Zhejiang University</a> &--> 
<a href="https://github.com/Westlake-AI" target="_blank" style="color:#1F50C0">Center for Artificial Intelligence Research and Innovation (CAIRI AI Lab)</a><br />
<br />
Location: E2-223, Westlake University, Dunyu Road #600, Xihu District, Hangzhou, Zhejiang, China.<br />
<!-- Location: Building 2-Room 508, Shilongshan Street #18, Xihu District, Hangzhou, Zhejiang, China<br /> -->
<class="staffshortcut">
 <A HREF="#News" style="color:#1F50C0">News</A> | 
 <A HREF="#Interest" style="color:#1F50C0">Research Interests</A> | 
 <A HREF="#Education" style="color:#1F50C0">Education</A> | 
 <A HREF="#Internship" style="color:#1F50C0">Internship</A> | 
 <A HREF="#Publications" style="color:#1F50C0">Publications</A> | 
 <A HREF="#Services" style="color:#1F50C0">Services</A> | 
 <A HREF="#Acknowledgement" style="color:#1F50C0">Acknowledgement</A> | 
 <A HREF="./Files/ZedongWang_CV.pdf" style="color:#1F50C0">CV</A> | 
 <!-- <A HREF="#Awards" style="color:#2a7ce0">Awards</A> -->
<br />
<br />

Email: jackywang28@outlook.com (prior); wangzedong@westlake.edu.cn <br />
[<a href="https://scholar.google.com/citations?hl=en&user=CEJ4pugAAAAJ" target="_blank" style="color:#1F50C0">Google Scholar</a>]  
[<a href="https://openreview.net/profile?id=~Zedong_Wang1" target="_blank" style="color:#1F50C0">OpenReview</a>] 
[<a href="https://twitter.com/ZedongWangAI" target="_blank" style="color:#1F50C0">Twitter (X)</a>]
[<a href="https://github.com/Jacky1128" target="_blank" style="color:#1F50C0">GitHub</a>] 
[<a href="https://www.linkedin.com/in/jacky-zedong-wang/" target="_blank" style="color:#1F50C0">LinkedIn</a>]
[<a href="https://orcid.org/0009-0000-0112-0491" target="_blank" style="color:#1F50C0">ORCID</a>] 
[<a href="https://dblp.org/pid/179/8811.html" target="_blank" style="color:#1F50C0">DBLP</a>] 
[<a href="https://www.researchgate.net/profile/Zedong-Wang-4" target="_blank" style="color:#1F50C0">ResearchGate</a>] 

<br />
<br />
<i>Welcome to contact me via email (jackywang28@outlook.com), Twitter (ZedongWangAI) or WeChat (JackyW1128) about research and internship.</i><br />
</td></tr></table>

<!-- 
<A NAME="Short Bio"><h2>Short Bio</h2></A>
  <div style="height:130px;overflow-y:auto;">
I am a Hong Kong-born AI researcher. I received my B.Eng. degree in Electronic and Information Engineering from <a href="https://en.wikipedia.org/wiki/Huazhong_University_of_Science_and_Technology"> Huazhong University of Science and Technology (HUST)</a>, in June, 2023. 
My research interests now center around Multi-modal Learning on Autonomous Driving and Beyond. I am also interested in Computer Vision from 3 aspects: (i) Data Mixing Augmentation and Label-Efficient Learning (Data-level); (ii) Efficient Network Architecture
Design (Network-level); (iii) Generative Models, e.g., Vector Quantization, Diffusion Models, on Computer Vision and Beyond. (Framework-
level). Currently, I am a visiting student at <a href="https://en.westlake.edu.cn/"> Westlake University</a> under <a href="https://scholar.google.com/citations?hl=zh-CN&user=Y-nyLGIAAAAJ"> Chair Prof. Stan Z. Li (IEEE Fellow, IAPR Fellow)</a>. 
I am also a remote research intern at <a href="https://www.mmlab-ntu.com/"> MMLab@NTU</a>, working with <a href="https://scholar.google.com/citations?hl=zh-CN&user=XdahAuoAAAAJ"> Dr. Chenyang Si</a>. At HUST, I was fortunate to work on few-shot
segmentation under <a href="https://scholar.google.com/citations?hl=zh-CN&user=qNCTLV0AAAAJ"> Prof. Xinggang Wang</a>. Previously, I was a research intern at <a href="http://mmlab.siat.ac.cn/"> SIAT-MMLab</a>, Chinese Academy of Sciences (CAS). 
I also interned at <a href="http://www.digitalearthlab.com.cn/"> Key Lab of Digital Earth Science</a>, CAS, 2020.
Life motto: <i>Pursue Eudaimonia</i>!
</div>
-->

<A NAME="News"><h2>News</h2></A>
  <!-- <div style="height:200px;overflow-y:auto;background:#ffffff;"> -->
  <div style="height:280px;overflow-y:auto;">
  <ul>
    <li><b> <font color="#A08244">[Feb. 2024]</font> </b> Hornored to serve as a <i>reviewer</i> at <i><a href="https://icml.cc/Conferences/2024" target="_blank" style="color:#1F28E6"> ICML 2024</a></i>, <i><a href="https://eccv2024.ecva.net" target="_blank" style="color:#1F28E6"> ECCV 2024</a></i>, and <i><a href="http://icpr2024.org" target="_blank" style="color:#1F28E6"> ICPR 2024</a></i>. </li></li>
    <li><b> <font color="#A08244">[Jan. 2024]</font> </b> One paper on <i>efficient network architecture design</i>, <i><a href="https://openreview.net/forum?id=XhYWgjqCrV" target="_blank" style="color:#1F28E6"> MogaNet</a></i>, is accepted by <b>ICLR 2024</b>. <i><a href="https://github.com/Westlake-AI/MogaNet" target="_blank" style="color:#1F28E6"> Code and weights</a></i> are all released on Github (114 stars)! Welcome to discuss, use, star and cite!</li></li>
    <li><b> <font color="#A08244">[Jan. 2024]</font> </b> Co-authored paper on <i>semi-supervised learning</i>, <i><a href="https://openreview.net/forum?id=dnqPvUjyRI" target="_blank" style="color:#1F28E6"> SemiReward</a></i>, is accepted by <b>ICLR 2024</b>. Congrats to <a href="https://scholar.google.com/citations?hl=en&user=SKTQTXwAAAAJ" target="_blank" style="color:#1F50C0">Siyuan Li</a>. </li></li>
    <li><b> <font color="#A08244">[Jan. 2024]</font> </b> Hornored to serve as an <i> emergency reviewer</i> for <i><a href="https://iclr.cc/Conferences/2024/CallForTinyPapers" target="_blank" style="color:#1F28E6"> ICLR 2024 TinyPapers</a></i>. </li></li>
    <li><b> <font color="#A08244">[Dec. 2023]</font> </b> Co-authored preprint on <i>self-supervised learning</i>, <i><a href="https://arxiv.org/abs/2401.00897" target="_blank" style="color:#1F28E6"> Masked Modeling on Vision and Beyond</a></i></b>. </li></li>
    <li><b> <font color="#A08244">[Nov. 2023]</font> </b> Engaged in <i>Westlake University Funded AI + Life Science Research Project</i> on <i>AI for Genomics</i> program.  </b> </li></li> 
    <li><b> <font color="#A08244">[Sep. 2023]</font> </b> Co-authored paper on <i>spatio-temporal prediction</i>, <i><a href="https://arxiv.org/abs/2203.10761" target="_blank" style="color:#1F28E6"> OpenSTL</a></i>, is accepted by <b>NeurIPS 2023</b>. Congrats to <a href="https://scholar.google.com/citations?user=6kTV6aMAAAAJ&hl=zh-CN" target="_blank" style="color:#1F50C0">Cheng Tan</a>. </li></li>
    <li><b> <font color="#A08244">[Jul. 2023]</font> </b> Got my B.Eng. degree from <i><a href="https://www.hust.edu.cn" target="_blank" style="color:#1F28E6"> Huazhong University of Science and Technology</a></i>! Special thanks to my supervisor <a href="https://scholar.google.com/citations?hl=zh-CN&user=qNCTLV0AAAAJ" target="_blank" style="color:#1F50C0">Prof. Xinggang Wang</a>!</li>
    <li><b> <font color="#A08244">[May. 2023]</font> </b> One preprint on <i>data augmentation</i>, <i><a href="https://arxiv.org/abs/2111.15454" target="_blank" style="color:#1F28E6"> SAMix</a></i>. The first method solving the 2 remaining challenges in mixup at once for both SL & SSL scenarios. </li>
    <li><b> <font color="#A08244">[May. 2023]</font> </b> One preprint on <i>efficient network architecture</i>, <i><a href="https://arxiv.org/abs/2111.15454" target="_blank" style="color:#1F28E6"> MogaNet</a></i>. A new family of pure convolutional architecture covering <b>5M~100M+</b> model scales with great performance. <i><a href="https://github.com/Westlake-AI/MogaNet" target="_blank" style="color:#1F3CDA"> Code and weights</a></i> are all released! Welcome to discuss, use, star and cite!</li>
    <li><b> <font color="#A08244">[Dec. 2022]</font> </b> Got my CS Ph.D. offer from <i><a href="https://en.westlake.edu.cn" target="_blank" style="color:#1F28E6"> Westlake University</a></i>! 
    <li><b> <font color="#A08244">[Nov. 2022]</font> </b> One preprint on <i>data augmentation</i>, <i><a href="https://arxiv.org/abs/2111.15454" target="_blank" style="color:#1F28E6"> OpenMixup</a></i>. The first comprehensive mixup benchmark for visual classification and more. </li>
    <li><b> <font color="#A08244">[Sep. 2022]</font> </b> Maintain an open-source toolbox, <i><a href="https://github.com/Westlake-AI/openmixup" target="_blank" style="color:#1F28E6"> OpenMixup</a></i> (549 stars), for both supervised, and unsupervised visual representation learning based on PyTorch. On updating! </li>
    <li><b> <font color="#A08244">[Jul. 2022]</font> </b> Fortunate to become <i>visiting student</i> in <i><a href="https://github.com/Westlake-AI" target="_blank" style="color:#1F28E6"> CAIRI AI Lab</a></i> at Westlake University. </li></li>
    <li><b> <font color="#A08244">[Sep. 2021]</font> </b> Fortunate to become <i>research intern</i> in <i><a href="https://www.hust.edu.cn" target="_blank" style="color:#1F28E6"> HUST Vision Lab</a></i>, supervised by <a href="https://scholar.google.com/citations?hl=zh-CN&user=qNCTLV0AAAAJ" target="_blank" style="color:#1F50C0">Prof. Xinggang Wang</a>. </li></li>
    <li><b> <font color="#A08244">[Jun. 2021]</font> </b> Fortunate to become <i>research intern</i> in <i><a href="https://mmlab.siat.ac.cn" target="_blank" style="color:#1F28E6"> SIAT-MMLab</a></i> at Shenzhen Institute of Advanced Technology (SIAT), Chinese Academy of Sciences. </li></li>

</ul>
</div>


<A NAME="Interest"><h2>Research Interests</h2></A>
Currently, I mainly focus on Multi-modal Learning and Multi-task Scene Understanding. I am also interested in Computer Vision on:
<ul>
    <li>Data-level: Data Mixing Augmentation and Label-Efficient Learning.</li>
    <li>Network-level: Efficient Network Architecture Design.</li>
    <li>Framework-level: Generation with Vector Quantization, Diffusion Models and more.</li>
</ul>
<br />


<A NAME="Education"><h2>Education</h2></A>
<ul>
<!--
    <li>2024.09-2029.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ph.D. at <a href="https://www.zju.edu.cn/" target="_blank" style="color:#2a7ce0">Zhejiang University</a> & <a href="https://en.westlake.edu.cn" target="_blank" style="color:#2a7ce0">Westlake University</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Supervisor: <a href="https://scholar.google.com/citations?hl=zh-CN&user=Y-nyLGIAAAAJ" target="_blank" style="color:#2a7ce0">Chair Prof. Stan Z. Li</a></li>
-->
    <li>2019.09-2023.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; B.Eng. in EE at <a href="https://www.hust.edu.cn" target="_blank" style="color:#1F50C0">Huazhong University of Science and Technology</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Supervisor: <a href="https://scholar.google.com/citations?hl=en&user=qNCTLV0AAAAJ" target="_blank" style="color:#1F50C0">Prof. Xinggang Wang</a>.</li>
</ul>
<br />

<A NAME="Internship"><h2>Internship</h2></A>
<ul>
<li>2024.03-now &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Research on multi-modal multi-task learning at <a href="https://hkust.edu.hk" target="_blank" style="color:#1F50C0">HKUST</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Advisor: <a href="https://scholar.google.com/citations?hl=en&user=OuSPv-AAAAAJ" target="_blank" style="color:#1F50C0">Prof. Dan Xu</a>.</li>
<!--<li>2024.02-now &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Research on generative models at <a href="https://www.mmlab-ntu.com/index.html" target="_blank" style="color:#2a7ce0">MMLab@NTU</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Advisor: <a href="https://scholar.google.com/citations?hl=zh-CN&user=XdahAuoAAAAJ" target="_blank" style="color:#2a7ce0">Dr. Chenyang Si</a>.</li>
--><li>2022.07-2024.03 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Research on representation learning at <a href="https://en.westlake.edu.cn" target="_blank" style="color:#1F50C0">Westlake University</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Advisor: <a href="https://scholar.google.com/citations?hl=en&user=Y-nyLGIAAAAJ" target="_blank" style="color:#1F50C0">Chair Prof. Stan Z. Li</a>.</li>
<li>2021.09-2023.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Research on few-shot semantic segmentation at <a href="https://www.hust.edu.cn" target="_blank" style="color:#1F50C0">HUST Vision Lab</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Advisor: <a href="https://scholar.google.com/citations?hl=en&user=qNCTLV0AAAAJ" target="_blank" style="color:#1F50C0">Prof. Xinggang Wang</a>.</li>
<li>2021.06-2021.09 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Research on semantic segmentation & text spotting at <a href="https://mmlab.siat.ac.cn" target="_blank" style="color:#1F50C0">MMLab@SIAT</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Advisor: <a href="https://scholar.google.com/citations?hl=zh-CN&user=9WhK1y4AAAAJ" target="_blank" style="color:#1F50C0">Dr. Bin Fu</a>.</li>
<li>2020.06-2021.04 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Research on remote sensing high-res semantic segmentation at <a href="http://www.digitalearthlab.com.cn" target="_blank" style="color:#1F50C0">CAS</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Advisor: <a href="https://scholar.google.com/citations?hl=zh-CN&user=TpX2C3cAAAAJ" target="_blank" style="color:#1F50C0">Dr. Xiaoping Du</a>.</li>
<!--<li>2019.07-2019.10 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Research on spatio-temporal remote sensing at <a href="https://carnegiescience.edu" target="_blank" style="color:#2a7ce0">Carnegie Inst. for Sci.</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Advisor: <a href="https://scholar.google.com/citations?hl=zh-CN&user=_L1i3RgAAAAJ" target="_blank" style="color:#2a7ce0">Dr. Yelu Zeng</a>.</li>
-->
</ul>
<br /> 


<A NAME="Publications"><h2>Publications</h2></A>

<p><b>Selected Preprints (*: Equal Contribution. †: Corresponding Author.)</b>: </p>
<font size="3"> 
<ul>

<table class="imgtable"><tr><td>
    <img src="https://github.com/Westlake-AI/openmixup/assets/55654777/1eb6065f-ac89-4995-9833-744ceab9540c" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://arxiv.org/abs/2310.03013" target="_blank" style="color:#1F50C0">Masked Modeling for Self-supervised Representation Learning on Vision and Beyond</a></b></font><br>
        <i> Siyuan Li*, Luyuan Zhang*, <b>Zedong Wang</b>, Di Wu, Lirong Wu, Zicheng Liu, Jun Xia, Cheng Tan, Yang Liu, Baigui Sun, Stan Z. Li† </a></i><br><i><b>ArXiv, 2023</b></i><br>
        [<a href= "https://arxiv.org/abs/2401.00897" target="_blank" style="color:#1F50C0">PDF</a>]
        [<a href="https://github.com/Lupin1998/Awesome-MIM" target="_blank" style="color:#1F50C0">Code</a>]
        [<a href="./Files/arXiv_2022_MogaNet_bibtex" target="_blank" style="color:#1F50C0">BibTeX</a>]
</p></td></tr></table>


<table class="imgtable"><tr><td>
    <img src="https://github.com/Jacky1128/Jacky1128.github.io/assets/55654777/716f17ad-987e-4542-b6c1-7099b824b90c" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://arxiv.org/abs/2211.03295" target="_blank" style="color:#1F50C0">OpenMixup: A Comprehensive Mixup Benchmark for Visual Classification</a></b></font><br>
        <i> Siyuan Li*, <b>Zedong Wang*</b>, Zicheng Liu, Di Wu, Cheng Tan, Weiyang Jin, Stan Z. Li† </a></i><br><i><b>ArXiv, 2022</b></i><br>
        [<a href= "https://arxiv.org/abs/2209.04851" target="_blank" style="color:#1F50C0">PDF</a>]
        [<a href="https://github.com/Westlake-AI/openmixup" target="_blank" style="color:#1F50C0">Code</a>]
        [<a href="./Files/arxiv_2022_OpenMixup_bibtex" target="_blank" style="color:#1F50C0">BibTeX</a>]
</p></td></tr></table>

<table class="imgtable"><tr><td>
    <img src="https://github.com/Jacky1128/Jacky1128.github.io/assets/55654777/dbe8267b-bc8a-481f-a11c-b0d2dda124b5" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://arxiv.org/abs/2211.03295" target="_blank" style="color:#1F50C0">Boosting Discriminative Visual Representation Learning with Scenario-Agnostic Mixup</a></b></font><br>
        <i> Siyuan Li*, Zicheng Liu*, <b>Zedong Wang*</b>, Di Wu, Zihan Liu, Stan Z. Li† </a></i><br><i><b>ArXiv, 2022</b></i><br>
        [<a href= "https://arxiv.org/abs/2111.15454" target="_blank" style="color:#1F50C0">PDF</a>]
        [<a href="https://github.com/Westlake-AI/openmixup" target="_blank" style="color:#1F50C0">Code</a>]
        [<a href="./Files/arXiv_2021_SAMix_bibtex" target="_blank" style="color:#1F50C0">BibTeX</a>]
</p></td></tr></table>


</ul>
<br />


<p><b>Conferences (As First Author)</b>: </p>
<font size="3"> 
<ul>

<table class="imgtable"><tr><td>
    <img src="https://github.com/Jacky1128/Jacky1128.github.io/assets/55654777/a8eb8475-1505-41f0-a2c0-5e3864de22bf" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://arxiv.org/abs/2211.03295" target="_blank" style="color:#1F50C0">MogaNet: Multi-order Gated Aggregation Network</a></b></font><br>
        <i> Siyuan Li*, <b>Zedong Wang*</b>, Zicheng Liu, Cheng Tan, Haitao Lin, Di Wu, Zhiyuan Chen, Jiangbin Zheng, Stan Z. Li† </a></i><br><i><b>The Twelfth International Conference on Learning Representations (ICLR), Vienna, Austria, 2024</b></i><br>
        [<a href= "https://arxiv.org/abs/2211.03295" target="_blank" style="color:#1F50C0">PDF</a>]
        [<a href="https://github.com/Westlake-AI/MogaNet" target="_blank" style="color:#1F50C0">Code</a>]
        [<a href= "https://zhuanlan.zhihu.com/p/582542948" target="_blank" style="color:#1F50C0">Zhihu</a>]
        [<a href="./Files/arXiv_2022_MogaNet_bibtex" target="_blank" style="color:#1F50C0">BibTeX</a>]
</p></td></tr></table>

</ul>
<br />


<p><b>Conferences (As Co-author)</b>: </p>
<font size="3"> 
<ul>

<table class="imgtable"><tr><td>
    <img src="https://github-production-user-asset-6210df.s3.amazonaws.com/44519745/273304810-c59589a3-8aff-4788-896c-5e099e73083e.png" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://arxiv.org/abs/2310.03013" target="_blank" style="color:#1F50C0">SemiReward: A General Reward Model for Semi-supervised Learning</a></b></font><br>
        <i> Siyuan Li*, Weiyang Jin*, <b>Zedong Wang</b>, Fang Wu, Zicheng Liu, Cheng Tan, Stan Z. Li† </a></i><br><i><b>The Twelfth International Conference on Learning Representations (ICLR), Vienna, Austria, 2024</b></i><br>
        [<a href= "https://arxiv.org/abs/2310.03013" target="_blank" style="color:#1F50C0">PDF</a>]
        [<a href="https://github.com/Westlake-AI/SemiReward" target="_blank" style="color:#1F50C0">Code</a>]
        [<a href="./Files/arXiv_2023_SemiReward_bibtex" target="_blank" style="color:#1F50C0">BibTeX</a>]
</p></td></tr></table>


<table class="imgtable"><tr><td>
    <img src="https://github-production-user-asset-6210df.s3.amazonaws.com/44519745/246222226-61e6b8e8-959c-4bb3-a1cd-c994b423de3f.png" style="border:1.2px solid #464646;padding:5px;border-radius:14px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="220px" />&nbsp;</td>
    <td align="left"><p>
        <font size="2pt" face="Georgia"><b><a href= "https://arxiv.org/abs/2306.11249" target="_blank" style="color:#1F50C0">OpenSTL: A Comprehensive Benchmark of Spatio-Temporal Predictive Learning</a></b></font><br>
        <i> Cheng Tan*, Siyuan Li*, Zhangyang Gao, Wenfei Guan, <b>Zedong Wang</b>, Zicheng Liu, Lirong Wu, Stan Z. Li† </a></i><br><i><b>The Thirty-Seventh Conference on Neural Information Processing Systems (NeurIPS), New Orleans, USA, 2023</b></i><br>
        [<a href= "https://arxiv.org/abs/2306.11249" target="_blank" style="color:#1F50C0">PDF</a>]
        [<a href="https://github.com/chengtan9907/OpenSTL" target="_blank" style="color:#1F50C0">Code</a>]
        [<a href= "https://zhuanlan.zhihu.com/p/640271275" target="_blank" style="color:#1F50C0">Zhihu</a>]
        [<a href="./Files/NIPS_2023_OpenSTL_bibtex" target="_blank" style="color:#1F50C0">BibTeX</a>]
</p></td></tr></table>   

</ul>
<br />


<p><b>Journals</b>: </p>
<font size="3"> 
<ul>

</ul>
<br />


<A NAME="Services"><h2>Services</h2></A>

<p><b>Program Committee Member | Reviewer</b>: </p>
<font size="3"> 
<ul>
<li>European Conference on Computer Vision (<b>ECCV</b>), 2024</li>
<li>International Conference on Pattern Recognition (<b>ICPR</b>), 2024</li>
<li>The Forty-First International Conference on Machine Learning (<b>ICML</b>), 2024</li>
<li>The Twelfth International Conference on Learning Representations (<b>ICLR</b>), 2024 (TinyPapers)</li>
</ul>
</font>
<br />
 
<p><b>Membership</b>: </p>
<font size="3"> 
<ul>
<li>China Society of Image and Graphics (CSIG), Student Member, 2023</li>
</ul>
</font>
<br />
<br />

<!-- 
<p><b>Invited Talk</b>: </p>
<font size="3"> 
<ul>
<li>2023/12/14: Talk on "Mixup Data Augmentation for Computer Vision" @ Chongqing Technology and Business University</li> [<a href="./Files/Mixup_Data_Augmentation_for_Computer_Vision_20231214.pdf" target="_blank" style="color:#2a7ce0">PPT</a>]
<li>2023/12/14: Talk on "Introduction to AI Research and Experience Sharing" @ Chongqing Technology and Business University</li>
</ul>
</font>
<br />
<br />

<p><b>Program committee member | Reviewer</b>: </p>
<font size="3"> 
<ul>
<li>Conference and Workshop on Neural Information Processing Systems (<b>NeurIPS</b>), 2022, 2023 (Main Track, Dataset and Benchmark Track)</li>
<li>International Conference on Machine Learning (<b>ICML</b>), 2022, 2023</li>
<li>International Conference on Learning Representations (<b>ICLR</b>), 2024</li>
<li>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022, 2023, 2024</li>
<li>International Conference on Computer Vision (<b>ICCV</b>), 2023</li>
<li>Conference on European Conference on Computer Vision (<b>ECCV</b>), 2022</li>
<li>AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2022, 2023, 2024</li>
<li>International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2022, 2023</li>
<li>ACM Multimedia (<b>ACMMM</b>), 2022</li>
<li>IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>)</li>
<li>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</li>
<li>IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2022, 2023, 2024</li>
<li>Electronic Research Archive (<b>ERA</b>)</li>
<li>Neural Computing & Applications (<b>NCA</b>)</li>
</ul>
</font>
<br />

</div>
-->

<!-- 
<A NAME="Awards"><h2>Awards</h2></A>
<font size="3"> 
<ul>
<li>2017, First Prize of Academic Scholarship, Zhejiang University | <font style="font-family:Microsoft YaHei">学业奖学金一等奖</font></li>
</ul>
</font>
 
<br />
<br /> -->

<A NAME="Acknowledgement"><h2>Acknowledgement</h2></A>
My research career cannot be possible without the generous support from all my awesome mentors and collaborators:
<ul>
<li>Prof. <a href="https://scholar.google.com/citations?hl=en&user=qNCTLV0AAAAJ" target="_blank" style="color:#1F50C0">Xinggang Wang</a>, Prof. <a href="https://yuzhou.vlrlab.net" target="_blank" style="color:#1F50C0">Yu Zhou</a>, Prof. Xin Yang at Huazhong University of Science and Technology (HUST).</li>
<li>Prof. <a href="https://scholar.google.com/citations?hl=en&user=Y-nyLGIAAAAJ" target="_blank" style="color:#1F50C0">Stan Z. Li</a>, Dr. <a href="https://scholar.google.com/citations?hl=en&user=SKTQTXwAAAAJ" target="_blank" style="color:#1F50C0">Siyuan Li</a>, Dr. <a href="https://scholar.google.com/citations?hl=en&user=EwMGZsgAAAAJ" target="_blank" style="color:#1F50C0">Zicheng Liu</a>, Dr. <a href="https://scholar.google.com/citations?hl=en&user=o5A23qIAAAAJ" target="_blank" style="color:#1F50C0">Haitao Lin</a>, Dr. <a href="https://scholar.google.com/citations?hl=en&user=egz8bGQAAAAJ" target="_blank" style="color:#1F50C0">Jiangbin Zheng</a>, Mr. Siqi Ma at Westlake University.</li>
<li>Prof. <a href="https://scholar.google.com/citations?hl=en&user=OuSPv-AAAAAJ" target="_blank" style="color:#1F50C0">Dan Xu</a>, Dr. <a href="https://scholar.google.com/citations?hl=en&user=ennCRJAAAAAJ" target="_blank" style="color:#1F50C0">Zhenxing Mi</a>, Dr. <a href="https://scholar.google.com/citations?hl=en&user=4OuUHYQAAAAJ" target="_blank" style="color:#1F50C0">Yuxin Wang</a>, Dr. <a href="https://scholar.google.com/citations?hl=en&user=kR5LuzgAAAAJ" target="_blank" style="color:#1F50C0">Yu Cai</a> at The Hong Kong University of Science and Technology (HKUST).</li>
<li>Dr. <a href="https://scholar.google.com/citations?hl=en&user=9WhK1y4AAAAJ" target="_blank" style="color:#1F50C0">Bin Fu</a>, Dr. Aozhong Zhang at SIAT-MMLab, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences.</li>
<li>Dr. <a href="https://scholar.google.com/citations?hl=en&user=TpX2C3cAAAAJ" target="_blank" style="color:#1F50C0">Xiaoping Du</a> at Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences.</li>
</ul>
Aside from research, I've been fortunate to meet my wonderful friends at various life moments. Whether we are still in touch or not, I appreciate all your support and wish you all the best.
<br />



<A NAME="Great Memories"><h2>Great Memories</h2></A>
<img src="https://github.com/Westlake-AI/openmixup/assets/55654777/d1d10bf2-f521-4860-a286-207c3af392e7" style="border:0.4px solid #464646;padding:5px;border-radius:14px;box-shadow:1.6px 1.6px #bbbbbb" alt="" width="198px" />&nbsp;</td>
<img src="https://github.com/Westlake-AI/openmixup/assets/55654777/889375a9-27d8-4975-bfa1-05b36916e021" style="border:0.4px solid #464646;padding:5px;border-radius:14px;box-shadow:1.6px 1.6px #bbbbbb" alt="" width="342px" />&nbsp;</td>
<img src="https://github.com/Westlake-AI/openmixup/assets/55654777/d4a10ac1-2dbc-4e41-b286-4c1ffbd2954d" style="border:0.4px solid #464646;padding:5px;border-radius:14px;box-shadow:1.6px 1.6px #bbbbbb" alt="" width="340px" />&nbsp;</td>
<img src="https://github.com/Westlake-AI/openmixup/assets/55654777/e55bbe34-3513-4cf0-8f6b-ef4c93f155ff" style="border:0.4px solid #464646;padding:5px;border-radius:14px;box-shadow:1.6px 1.6px #bbbbbb" alt="" width="420px" />&nbsp;</td>
<img src="https://github.com/Westlake-AI/openmixup/assets/55654777/bd91d46c-0c14-484d-ac46-650f2c682e23" style="border:0.4px solid #464646;padding:5px;border-radius:14px;box-shadow:1.6px 1.6px #bbbbbb" alt="" width="485px" />&nbsp;</td>


<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5x3ebj080sx&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>
 

<div id="article"></div>
<div id="back_top">
<div class="arrow"></div>
<div class="stick"></div>
</div>

<script>
$(function(){
    $(window).scroll(function(){  //If scroll
        var scrollt = document.documentElement.scrollTop + document.body.scrollTop; //Getting Height after scroll
        if( scrollt >400 )
        {  
            $("#back_top").fadeIn(400); 
        }
        else
        {
            $("#back_top").stop().fadeOut(400);
        }
    });

    $("#back_top").click(function(){ 

        $("html,body").animate({scrollTop:"0px"}, 200);

    }); 

});
</script>


All Rights Reserved by Zedong Wang. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.


<!-- <font size="2"; color="#A0A0A0";>
<p style="text-align:center">Updating time: 2022.06.01</p>
</font> -->


</body>
</html>
